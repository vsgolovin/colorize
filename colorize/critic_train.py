from typing import Optional
import numpy as np
import torch
from torch import nn, optim
from torch.utils.data import DataLoader
from torchvision import transforms as T
from dataset_utils import LabColorizationDataset
from critics import DeOldify_Discriminator
from loss_functions import GANLoss
from visualize import rescale4resnet
from tqdm import tqdm

# Folder with RGB original pictures
REAL_IMAGE_FOLDER = 'data/imagenet_tiny/train'
# Folder with RGB pictures generated by the latest version of the generator
FAKE_INAGE_FOLDER = 'data/model_output/ResNet18'
BATCH_SIZE = 32
EVAL_EVERY = 50
TOTAL_ITERATIONS = 1000


class Discriminator(nn.Module):
    def __init__(self, net_D: nn.Module, lr: float = 2e-4):
        super().__init__()
        self.device = torch.device(
            "cuda" if torch.cuda.is_available() else "cpu")
        self.net_D = net_D.to(self.device)
        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)
        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr)

    def setup_input(self, data):
        self.real_L = data['real_L'].to(self.device)
        # self.fake_L = data['fake_L'].to(self.device) # Не нужно
        self.real_ab = data['real_ab'].to(self.device)
        self.fake_ab = data['fake_ab'].to(self.device)

    def get_loss(self):
        fake_image = torch.cat([self.real_L, self.fake_ab], dim=1)
        fake_preds = self.net_D(fake_image)
        self.loss_D_fake = self.GANcriterion(fake_preds, False)
        real_image = torch.cat([self.real_L, self.real_ab], dim=1)
        real_preds = self.net_D(real_image)
        self.loss_D_real = self.GANcriterion(real_preds, True)
        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5
        return self.loss_D
        # self.loss_D.backward()

    def optimize(self):
        self.net_D.train()
        self.opt_D.zero_grad()
        self.get_loss().backward()
        self.opt_D.step()


def train_discriminator(
        disc: nn.Module,
        train_dataloader: DataLoader,
        val_dataloader: Optional[DataLoader] = None,
        eval_every: int = EVAL_EVERY,
        total_iterations: int = TOTAL_ITERATIONS):
    cur_iter = 0
    cur_loss = 0.0
    cur_samples = 0
    train_loss = []
    val_loss = []
    pbar = tqdm(total=eval_every, desc='0 iter')
    while True:
        for data in train_dataloader:
            disc.setup_input(data)
            disc.optimize()
            L = len(data['real_L'])
            cur_loss += disc.loss_D.item() * L
            cur_samples += L
            pbar.update(1)
            cur_iter += 1
            # actions for current 'eval every'
            if cur_iter % eval_every == 0:
                pbar.close()
                train_loss.append(cur_loss / cur_samples)
                print(f'\n  Discriminator train loss: {train_loss[-1]:.2e}')
                cur_loss = 0.0
                cur_samples = 0
                pbar = tqdm(total=eval_every,
                            desc=f'{cur_iter} iter')
            if cur_iter >= total_iterations:
                pbar.close()
                return np.array(train_loss), np.array(val_loss)


def main():
    net = DeOldify_Discriminator()
    disc = Discriminator(net_D=net)
    train_dataset = LabColorizationDataset(
        real_image_folder=REAL_IMAGE_FOLDER,
        fake_image_folder=FAKE_INAGE_FOLDER,
        transforms=T.Compose([
            rescale4resnet,
            T.RandomResizedCrop(224)
            ]))  # No random transforms!!!
    train_dataloader = DataLoader(
        train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    train_discriminator(disc, train_dataloader)


if __name__ == '__main__':
    main()
